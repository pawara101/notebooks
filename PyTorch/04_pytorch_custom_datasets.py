# -*- coding: utf-8 -*-
"""04_pytorch_custom_datasets.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1AxGKtzvCdBxu-UDhIUw6KRF6F26cHYXh

# pyTorch custom dataset Notebook.
* here using own dataset with pytorch.
* to do that we use custom dataset.

## 0. Import PyTorch and setup device agnostic code
"""

import torch
from torch import nn

torch.__version__

## Setup Device agnostic code
device = "cuda" if torch.cuda.is_available() else "cpu"

print(device)

"""## 1. Get Data
- this dataset is a subset of Food101 dataset.
- our dataset starts with 3 classes of food and only 10% of images(~75% trainning,25% testing)
"""

import requests
import zipfile
from pathlib import Path

## setup a path
data_path = Path("data/")
image_path = data_path / "pizza_steak_sushi"


if image_path.is_dir():
  print(f"{image_path} directory already exists... no need to download")

else:
  print(f"{image_path} does not exists, creating one....")
  image_path.mkdir(parents=True,exist_ok=True)


with open(data_path / "pizza_steak_sushi.zip", "wb") as f:
  request = requests.get("https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip")
  print(f"Downloading data....")

  f.write(request.content)

## Unzip file
with zipfile.ZipFile(data_path/"pizza_steak_sushi.zip","r") as zip_ref:
  print("Unzipping data....")
  zip_ref.extractall(image_path)

image_path

"""## 2. Becoming one with the data(data preperation and exploaration)"""

import os

def walk_through_dir(dir_path):

  for dir_path, dirnames, filenames in os.walk(dir_path):
    print(f"There are {len(dirnames)} directories and {len(filenames)} images in {dir_path}")

walk_through_dir(image_path)

## Setup trainning and testing paths
train_dir = image_path / "train"
test_dir = image_path /"test"

train_dir, test_dir

"""### 2.1 Visualizing Image
1. Get all of the Image paths
2. Pick a random image path using `random.choice()`
3. Get the image class name using `pathlib.Path.parent.stem()`
4. Open the image using Pyhton PIL
5. show image and print metadata.
"""

import random
from PIL import Image

#set seed
random.seed(42)

# 1. get all image paths
image_path_list = list(image_path.glob("*/*/*.jpg"))

# 2. Pick a random image path
random_image_path = random.choice(image_path_list)


# 3. Get image class from path name
image_class = random_image_path.parent.stem  ## stem Extracts the basename of the parent directory, which is assumed to represent the image class.

# 4. Open Image
img = Image.open(random_image_path)

# 5. Print Metadata
print(f"Random Image path : {random_image_path}")
print(f"Image class : {image_class}")
print(f'Image height : {img.height}')
print(f'Image width : {img.width}')
img

## try to visualise with matplotlib
import numpy as np
import matplotlib.pyplot as plt

# Turn image into an array
img_as_array =np.asarray(img)

# plot with matplot lib
plt.figure(figsize=(10,7))
plt.imshow(img_as_array)
plt.title(f"Image class : {image_class} | Image shape : {img_as_array.shape} --> [height,width,colour channels]")
plt.axis(False)
plt.show()

"""## 3. Transform data
- Before image data with PyTorch:
    1. Turn target data into tensors.
  
"""

import torch
from torch.utils.data import DataLoader
from torchvision import datasets, transforms

"""### 3.1 Transforming data with `torchvision.transforms`

"""

## write a trasnform for image
data_transform = transforms.Compose([
    ## Resize the image
    transforms.Resize(size=(64,64)),
    # Flip the image randomly hrozontally
    transforms.RandomHorizontalFlip(p=0.5),
    # Turn image into a torch.tensor
    transforms.ToTensor()
])

data_transform(img).shape

def plot_transformed_images(image_paths,transform,n=3,seed=42):

  if seed:
    random.seed(seed)
  random_image_paths = random.sample(image_paths,k=n)

  for image_path in random_image_paths:
    with Image.open(image_path) as f:
      fig,ax = plt.subplots(nrows=1,ncols=2)
      ax[0].imshow(f)
      ax[0].set_title(f"Original\nSize : {f.size}")
      ax[0].axis(False)

      # Transform and plot target image
      transformed_image = transform(f).permute(1,2,0)
      ax[1].imshow(transformed_image)
      ax[1].set_title(f"Transformed\nShape : {transformed_image.shape}")
      ax[1].axis("off")

      fig.suptitle(f"Class: {image_path.parent.stem}",fontsize=16)

plot_transformed_images(image_paths=image_path_list,
                        transform=data_transform,
                        n=3,
                        seed=42)

"""## 4. Option 01 : Loading Image using `ImageFolder`"""

## Use Image folder to create dataset
from torchvision import datasets
train_data = datasets.ImageFolder(root=train_dir,
                                  transform=data_transform,
                                  target_transform=None)

test_data  = datasets.ImageFolder(root=test_dir,
                                  transform=data_transform)

train_data,test_data

## Get class names as a list.
class_names = train_data.classes
class_names

## Get class names as a Dict.
class_dict = train_data.class_to_idx
class_dict

# check lengths
len(train_data),len(test_data)

train_data.samples[0]

len(train_data[0])

## Index on train_data dataset to get single image and label
img,label = train_data[0][0],train_data[0][1]
print(f"Image Tensor :\n {img}")
print(f"Image shape : {img.shape}")
print(f"Image datatype : {img.dtype}")
print(f"Image Label : {label}")
print(f"Label datatype : {type(label)}")

## Reaarange order of dimensions
img_permute = img.permute(1,2,0)

## Print out different shapes
print(f"Original shape : {img.shape} => [colour channels,height,width]")
print(f"Image permute : {img_permute.shape} => [height,width,colour channel]")

# Plot the image
plt.figure(figsize=(10,7))
plt.imshow(img_permute)
plt.axis(False)
# plt.title(class_name[label])

"""### 4.1 Turn loaded images into `DataLoaders`
* A `DataLoader`
"""

# turn train and test data sets into DataLoaders
from torch.utils.data import DataLoader
BATCH_SIZE = 1
train_dataloader = DataLoader(dataset=train_data,
                              batch_size=1,
                              num_workers=1,
                              shuffle=True)
test_dataloader = DataLoader(dataset = test_data,
                             batch_size=1,
                             num_workers=1,
                             shuffle=True)

train_dataloader,test_dataloader

len(train_dataloader),len(test_dataloader)

img,label= next(iter(train_dataloader))

# Batch size will now be 1.
print(f"Image shape : {img.shape} => [batch_size,color_channels,height,width]")
print(f"Label shape : {label.shape}")

"""## 5. Option 2: Loading Image using a custom dataset.
1. want to be able to load images from file.
2. want to be able to get class names from the dataset.
3. want to be able to get classes as dictionary from Datasets.

pros:
* Can create a `dataset` out of almost anything.
* Not limited to PyTorch pre-built `Datset` functions.

Cons:
* prone to errors and performance issue.
"""

import os
import pathlib
import torch

from PIL import Image
from torch.utils.data import Dataset
from torchvision import transforms
from typing import Tuple,Dict,List

## Instance of torchvision.
train_data.classes,train_data.class_to_idx

"""### 5.1 Creating a helper function to get class names.
We want a function to;
- get class names using `os.scandir()`
- Raise an error if class names are not found.
- Turn the class names into a dict.
"""

# setup path for target directory.
target_directory = train_dir
print(f"Target dir : {target_directory}")

class_names_found = sorted([entry.name for entry in list(os.scandir(target_directory))])
class_names_found

def find_classes(directory: str) -> Tuple[List[str],Dict[str,int]]:
  """
  Finds the class folder names in a target directory..
  """

  #1. Get the class names by scanning the target directory.
  classes = sorted(entry.name for entry in os.scandir(directory) if entry.is_dir())

  #2. raise an error if class names could not be found
  if not classes:
    raise FileNotFoundError(f"Could not find any classes in {directory} ....")

  #3. Create dictionary of index labels
  class_to_idx = {class_name: i for i , class_name in enumerate(classes)}
  return classes, class_to_idx

find_classes(target_directory)

"""### 5.2 Create a custom `Dataset` to replicate `ImageFolder`
To create own cutom dataset
1. Subclass `torch.utils.Dataset`
2. Init our subclass with a target directory
3. Create several attributes
  * paths
  * transform
  * classes
  * class_to_idx
4. Create a function to load images.
5. Overwrite `__len()__` method
6. Overwrite the `__getitem()__`
"""

## write a custom dataset
from torch.utils.data import Dataset

# 1. Subclass torch.utils.data.Dataset
class ImageFolderCustom(Dataset):
  # 2. Imitialize our cutom dataset
  def __init__(self,
               targ_dir: str,
               transform=None):
    # 3. Create class attributes.
    self.paths = list(pathlib.Path(targ_dir).glob("*/*.jpg"))
    # setup transforms
    self.transform = transform
    # Create classes
    self.classes,self.class_to_idx = find_classes(targ_dir)


  # 4. create a function to load images.
  def load_image(self,index:int) -> Image.Image:
    "Opens an image via a path and returns it."
    image_path = self.paths[index]
    return Image.open(image_path)

  # 5. Overwrite __len()__
  def __len__(self) -> int:
    "Returns the total numer of samples."
    return(len(self.paths))

  # 6. Overwrite __getitem__() method to return
  def __getitem__(self,index:int) -> Tuple[torch.Tensor, int]:
    "Returns the one sample of data, data and label(X,y)"
    img  = self.load_image(index)
    class_name = self.paths[index].parent.name #
    class_idx = self.class_to_idx[class_name]

    # Transform if necessary.
    if self.transform:
      return self.transform(img),class_idx

    else:
      return img, class_idx # return data, label (X, y)

# Create a transform
from torchvision import transforms
train_transforms = transforms.Compose([
    transforms.Resize(size=(64,64)),
    transforms.RandomHorizontalFlip(p=0.5),
    transforms.ToTensor()
])

test_transforms = transforms.Compose([
    transforms.Resize(size=(64,64)),
    transforms.ToTensor()
])

# test out ImageFolderCustom
train_data_custom = ImageFolderCustom(targ_dir=train_dir,
                                      transform=train_transforms)

test_data_custom = ImageFolderCustom(targ_dir=test_dir,
                                      transform=test_transforms)
train_data_custom,test_data_custom

train_data_custom.classes

train_data_custom.load_image(index=0)

# Check for equality amongst our custom Dataset and ImageFolder Dataset
print((len(train_data_custom) == len(train_data)) & (len(test_data_custom) == len(test_data)))
print(train_data_custom.classes == train_data.classes)
print(train_data_custom.class_to_idx == train_data.class_to_idx)

"""### 5.3 Create a function to display random images.
1. Take in a `Dataset` and a number of other parameters.
2. To prevent the display getting out of hand
3. set the random sample seed for reproducaility.
4. Get a list of random sample indexes from the target dataset.
5. Setup a matplotlib plot.
6. Loop thorugh the random sample images and plot with matplotlib.
7. Make sure the dimesions of our images line up with matplotlib.

"""

# 1. create a function to take in dataset.
def display_random_iamges(dataset: torch.utils.data.Dataset,
                          classes: List[str] = None,
                          n: int =10,
                          display_shape :bool = True,
                          seed:int =None):

  #2. adjust display if n is too high.
  if n > 10:
    n =10
    display_shape = False
    print(f"For display purposes, n shouldn't be larger than 10, setting to 10 and removing shape display.")
  #3. Set seed
  if seed:
    random.seed(seed)

  #4. Get random sample indexes
  random_samples_idx = random.sample(range(len(dataset)),k=n)

  #5. Setup plot
  plt.figure(figsize=(16,8))

  #6. loop through random indexes and plot
  for i, targ_sample in enumerate(random_samples_idx):
    targ_image,targ_label = dataset[targ_sample][0],dataset[targ_sample][1]

    #7. Adjust Tensor dim for plotting
    targ_image_adjust = targ_image.permute(1,2,0)

    # plot adjusted samples
    plt.subplot(1,n,i+1)
    plt.imshow(targ_image_adjust)
    plt.axis(False)

    if classes:
      title = f"Class : {classes[targ_label]}"

      if display_shape:
        title = title + f"\nshape: {targ_image_adjust.shape}"

      plt.title(title)

# Display random images from image folder.
display_random_iamges(train_data,
                      n=5,
                      classes=class_names,
                      seed=None)

"""### 5.4 Turn custom loaded images into `DataLoaders`"""

from torch.utils.data import DataLoader
BATCH_SIZE = 32
num_workers = os.cpu_count()
train_dataloader_custom = DataLoader(dataset=train_data_custom,
                                     batch_size=BATCH_SIZE,
                                     num_workers=num_workers,
                                     shuffle=True)

test_dataloader_custom = DataLoader(dataset=test_data_custom,
                                    batch_size=BATCH_SIZE,
                                    num_workers=num_workers,
                                    shuffle=True)


train_dataloader_custom,test_dataloader_custom

## Get image and label from cutom dataloader
img_custom,label_custom = next(iter(train_dataloader_custom))

# print out the shape
img_custom.shape,label_custom.shape

"""## 6. Other forms if transform
> Data augmentation is the process of artificially adding diversity to trainning data.
> Look at the same image but from different perspectives.

Lets take a one particular type of data augmentation.
"""

## Lets look at trivial augment
from torchvision import transforms

train_transform = transforms.Compose([
    transforms.Resize(size=(224,224)),
    transforms.TrivialAugmentWide(num_magnitude_bins=31),
    transforms.ToTensor()
])

test_transform = transforms.Compose([
    transforms.Resize(size=(224,224)),
    transforms.ToTensor()
])

# Get all the image paths
image_path_list = list(image_path.glob("*/*/*.jpg"))
image_path_list[:10]

# Plot random trasnformed images
plot_transformed_images(
    image_paths=image_path_list,
    transform=train_transform,
    n=3,
    seed=None
)

"""## 7. Model 0: TinyVGG without data augmentation.

Lets replicate TinyVGG from cnn explainer website.

### 7.1 Create transforms and loading data for model 0
"""

# create simple transform
simple_transform = transforms.Compose([
    transforms.Resize(size=(64,64)),
    transforms.ToTensor()
])

# 1. Load and transform data
from torchvision import datasets
train_data_simple = datasets.ImageFolder(root=train_dir,
                                         transform=simple_transform)

test_data_simple = datasets.ImageFolder(root=test_dir,
                                        transform=simple_transform)

# 2. Turn the database into DataLoaders.
import os
from torch.utils.data import DataLoader

# Setup batch size and number of workers
BATCH_SIZE = 32
NUM_WORKERS = os.cpu_count()

# create DataLoaders

train_dataloader_simple = DataLoader(dataset=train_data_simple,
                                      batch_size=BATCH_SIZE,
                                     shuffle=True,
                                     num_workers=NUM_WORKERS)

test_dataloader_simple = DataLoader(dataset=test_data_simple,
                                    batch_size=BATCH_SIZE,
                                    shuffle=True,
                                    num_workers=NUM_WORKERS)

"""### 7.2 Create TinyVGG model Class.

"""

class TinyVGG(nn.Module):
  '''

  '''
  def __init__(self,input_shape:int,
               hidden_units:int,
               output_shape:int) -> None:

    super().__init__()

    self.conv_block_1 = nn.Sequential(
        nn.Conv2d(in_channels=input_shape,
                  out_channels=hidden_units,
                  kernel_size=3,
                  stride=1,
                  padding=0),
        nn.ReLU(),
        nn.Conv2d(in_channels=hidden_units,
                      out_channels=hidden_units,
                      kernel_size=3,
                      stride=1,
                      padding=0),
        nn.ReLU(),
        nn.MaxPool2d(kernel_size=2,
                     stride=2)
    )

    self.conv_block_2 = nn.Sequential(
        nn.Conv2d(in_channels=hidden_units,
                  out_channels=hidden_units,
                  kernel_size=3,
                  stride=1,
                  padding=0),
        nn.ReLU(),
        nn.Conv2d(in_channels=hidden_units,
                      out_channels=hidden_units,
                      kernel_size=3,
                      stride=1,
                      padding=0),
        nn.ReLU(),
        nn.MaxPool2d(kernel_size=2,
                     stride=2)
    )

    self.classifier = nn.Sequential(
        nn.Flatten(),
        nn.Linear(in_features=hidden_units*13*13,
                  out_features=output_shape)
    )


  def forward(self,x):
    x = self.conv_block_1(x)
    # print(x.shape)
    x = self.conv_block_2(x)
    # print(x.shape)
    x = self.classifier(x)
    # print(x.shape)
    return x

torch.manual_seed(42)

model_0 = TinyVGG(input_shape=3,
                  hidden_units=10,
                  output_shape=len(class_names)).to(device)

model_0

"""### 7.3 Try a forward pass on asingle image"""

image_batch,label_batch = next(iter(train_dataloader_simple))
image_batch.shape,label_batch.shape

model_0(image_batch.to(device))

"""### 7.4 Use `torchinfo` to get idea of shape going through our model."""

# Install torchinfo
try:
  import torchinfo
except:
  ! pip install torchinfo
  import torchinfo

from torchinfo import summary

summary(model_0,input_size=[1,3,64,64])

"""### 7.5 Create test and train loop functions
* `train_step()` - takes in a model and dataloader and trains the model on the dataloader.
* `test_step()` - takes in a model and dataloader and evaluates the model on the dataloader.
"""

# ##Create train_step()

# def train_step(model:torch.nn.Module,
#                dataloader: torch.utils.data.DataLoader,
#                loss_fn: torch.nn.Module,
#                optimizer: torch.optim.Optimizer,
#                device:device):

#   ## Put the model in train mode
#   model.train()

#   # setup train loss and train accuracy values.
#   train_loss,train_acc =0,0

#   ## Loop through data loader data batches.
#   for batch, (X,y) in enumerate(dataloader):
#     # send data to the target device.
#     X, y = X.to(device), y.to(device)


#     # 1. forward Pass
#     y_pred = model(X)

#     # 2. Calculate the loss
#     loss = loss_fn(y_pred,y)
#     train_loss += loss.item()

#     # 3. Optimizer zero grad
#     optimizer.zero_grad()

#     # 4. Loss backward
#     loss.backward()

#     # 5. Optimizer step
#     optimizer.step()

#     # Calculate the accuracy metric
#     y_pred_class = torch.argmax(torch.softmax(y_pred,dim=1),dim=1)

#   # Adjust metrics to get average loss and accuracy per batch.
#   train_loss = train_loss /len(dataloader)
#   train_acc = train_acc/ len(dataloader)

#   return train_loss,train_acc


def train_step(model: torch.nn.Module,
               dataloader: torch.utils.data.DataLoader,
               loss_fn: torch.nn.Module,
               optimizer: torch.optim.Optimizer):
    # Put model in train mode
    model.train()

    # Setup train loss and train accuracy values
    train_loss, train_acc = 0, 0

    # Loop through data loader data batches
    for batch, (X, y) in enumerate(dataloader):
        # Send data to target device
        X, y = X.to(device), y.to(device)

        # 1. Forward pass
        y_pred = model(X)

        # 2. Calculate  and accumulate loss
        loss = loss_fn(y_pred, y)
        train_loss += loss.item()

        # 3. Optimizer zero grad
        optimizer.zero_grad()

        # 4. Loss backward
        loss.backward()

        # 5. Optimizer step
        optimizer.step()

        # Calculate and accumulate accuracy metric across all batches
        y_pred_class = torch.argmax(torch.softmax(y_pred, dim=1), dim=1)
        train_acc += (y_pred_class == y).sum().item()/len(y_pred)

    # Adjust metrics to get average loss and accuracy per batch
    train_loss = train_loss / len(dataloader)
    train_acc = train_acc / len(dataloader)
    return train_loss, train_acc

# ## Create a test_step()

# def test_step(model:torch.nn.Module,
#               dataloader: torch.utils.data.DataLoader,
#               loss_fn:torch.nn.Module,device:device):
#   ## Put the model in train mode
#   model.eval()

#   ## setup test loss and test acc
#   test_loss,test_acc = 0 ,0

#   # Loop through the data loader data batches.
#   for batch,(X,y) in enumerate(dataloader):
#     # send data to target device.
#     X,y = X.to(device),y.to(device)

#     # 1. Forward pass
#     test_pred_logits = model(X)

#     # 2. Calculate and accumelate the loss.
#     loss = loss_fn(test_pred_logits, y)
#     test_loss += loss.item()

#     # Calculate and accumelate the accuracy.
#     test_pred_labels = test_pred_logits.argmax(dim=1)
#     test_acc += ((test_pred_labels == y).sum().item()/len(test_pred_labels))

#     # Adjust metrics to get average loss and accuracy per batch
#     test_loss = test_loss / len(dataloader)
#     test_acc = test_acc / len(dataloader)
#     return test_loss, test_acc


def test_step(model: torch.nn.Module,
              dataloader: torch.utils.data.DataLoader,
              loss_fn: torch.nn.Module):
    # Put model in eval mode
    model.eval()

    # Setup test loss and test accuracy values
    test_loss, test_acc = 0, 0

    # Turn on inference context manager
    with torch.inference_mode():
        # Loop through DataLoader batches
        for batch, (X, y) in enumerate(dataloader):
            # Send data to target device
            X, y = X.to(device), y.to(device)

            # 1. Forward pass
            test_pred_logits = model(X)

            # 2. Calculate and accumulate loss
            loss = loss_fn(test_pred_logits, y)
            test_loss += loss.item()

            # Calculate and accumulate accuracy
            test_pred_labels = test_pred_logits.argmax(dim=1)
            test_acc += ((test_pred_labels == y).sum().item()/len(test_pred_labels))

    # Adjust metrics to get average loss and accuracy per batch
    test_loss = test_loss / len(dataloader)
    test_acc = test_acc / len(dataloader)
    return test_loss, test_acc

"""### 7.6 Creating a `train()` function to combine `train_step()` and `test_step()`"""

# from tqdm.auto import tqdm

# # 1. create a train function
# def train(model: torch.nn.Module,
#           train_dataloader : torch.utils.data.DataLoader,
#           test_dataloader : torch.utils.data.DataLoader,
#           optimizer: torch.optim.Optimizer,
#           loss_fn:torch.nn.Module = nn.CrossEntropyLoss(),
#           epochs: int =5):

#   # Create empty list dictionary
#   results = {
#       "train_loss":[],
#       "train_acc":[],
#       "test_loss":[],
#       "test_acc":[]
#   }

#   # 3. Loop through trainning and testing steps for number of epochs.
#   for epoch in tqdm(range(epochs)):
#     train_loss,train_acc = train_step(model=model,
#                                       dataloader=train_dataloader,
#                                       loss_fn = loss_fn,
#                                       optimizer=optimizer,
#                                       device=device)

#     test_loss,test_acc = test_step(model=model,
#                                    dataloader=test_dataloader,
#                                    loss_fn=loss_fn,
#                                    device=device)

#     # 4. Print
#     print(f"Epoch : {epoch} | Train loss : {train_loss:.4f} | Test acc : {test_acc:.4f} | Test loss : {test_loss:.4f} | Test acc : {test_acc:.4f}")

#     # 5. update result dictionary
#     results['train_loss'].append(train_loss)
#     results['train_acc'].append(train_acc)
#     results['test_loss'].append(test_loss)
#     results['test_acc'].append(train_acc)


#     #
#     return results



from tqdm.auto import tqdm

# 1. Take in various parameters required for training and test steps
def train(model: torch.nn.Module,
          train_dataloader: torch.utils.data.DataLoader,
          test_dataloader: torch.utils.data.DataLoader,
          optimizer: torch.optim.Optimizer,
          loss_fn: torch.nn.Module = nn.CrossEntropyLoss(),
          epochs: int = 5):

    # 2. Create empty results dictionary
    results = {"train_loss": [],
        "train_acc": [],
        "test_loss": [],
        "test_acc": []
    }

    # 3. Loop through training and testing steps for a number of epochs
    for epoch in tqdm(range(epochs)):
        train_loss, train_acc = train_step(model=model,
                                           dataloader=train_dataloader,
                                           loss_fn=loss_fn,
                                           optimizer=optimizer)
        test_loss, test_acc = test_step(model=model,
            dataloader=test_dataloader,
            loss_fn=loss_fn)

        # 4. Print out what's happening
        print(
            f"Epoch: {epoch+1} | "
            f"train_loss: {train_loss:.4f} | "
            f"train_acc: {train_acc:.4f} | "
            f"test_loss: {test_loss:.4f} | "
            f"test_acc: {test_acc:.4f}"
        )

        # 5. Update results dictionary
        results["train_loss"].append(train_loss)
        results["train_acc"].append(train_acc)
        results["test_loss"].append(test_loss)
        results["test_acc"].append(test_acc)

    # 6. Return the filled results at the end of the epochs
    return results

"""### 7.7 Train and evaluate model 0"""

# # set random seed
# torch.manual_seed(42)
# torch.cuda.manual_seed(42)

# # set Number of epochs
# NUM_EPOCHS = 5

# # Recreate an instance of TinyVGG
# model_0 = TinyVGG(input_shape=3,
#                   hidden_units=10,
#                   output_shape=len(train_data.classes)).to(device)

# # setup the loss function
# loss_fn = nn.CrossEntropyLoss()
# optimizer = torch.optim.Adam(params=model_0.parameters(),
#                              lr=0.001)

# # start the timer
# from timeit import default_timer as timer
# start_time = timer()


# # Train model_0
# model_0_results = train(model=model_0,
#                         train_dataloader=train_dataloader_simple,
#                         test_dataloader=test_data_simple,
#                         optimizer=optimizer,
#                         loss_fn=loss_fn,
#                         epochs=NUM_EPOCHS)
# #
# end_time = timer()

# print(f"Total trainning time : {end_time-start_time:.3f} seconds")






# Set random seeds
torch.manual_seed(42)
torch.cuda.manual_seed(42)

# Set number of epochs
NUM_EPOCHS = 5

# Recreate an instance of TinyVGG
model_0 = TinyVGG(input_shape=3, # number of color channels (3 for RGB)
                  hidden_units=10,
                  output_shape=len(train_data.classes)).to(device)

# Setup loss function and optimizer
loss_fn = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(params=model_0.parameters(), lr=0.001)

# Start the timer
from timeit import default_timer as timer
start_time = timer()

# Train model_0
model_0_results = train(model=model_0,
                        train_dataloader=train_dataloader_simple,
                        test_dataloader=test_dataloader_simple,
                        optimizer=optimizer,
                        loss_fn=loss_fn,
                        epochs=NUM_EPOCHS)

# End the timer and print out how long it took
end_time = timer()
print(f"Total training time: {end_time-start_time:.3f} seconds")

model_0_results

"""### 7.8 Plot the loss curve of Model 0

A **loss curve** is a method to model's progress over the time.
"""

# get model_0_results keys
model_0_results.keys()

def plot_loss_curves(results: Dict[str,List[float]]):

  # get the loss values of the results dictionary
  loss = results["train_loss"]
  test_loss = results["test_loss"]

  # get the accuracy
  accuracy = results['train_acc']
  test_accuracy = results['test_acc']


  # figure out how many epochs there were
  epochs = range(len(results["train_loss"]))

  # setup a plot
  plt.figure(figsize=(15,7))


  # plot the loss
  plt.subplot(1,2,1)
  plt.plot(epochs,loss,label="train_loss")
  plt.plot(epochs,test_loss,label="test_loss")
  plt.title("loss")
  plt.xlabel("Epochs")
  plt.legend()

  plt.subplot(1,2,2)
  plt.plot(epochs,accuracy,label="train_accuracy")
  plt.plot(epochs,test_accuracy,label="test_accuarcy")
  plt.title("Accuracy")
  plt.xlabel("Epochs")
  plt.legend()

plot_loss_curves(model_0_results)

"""## 8. What should ideal curve looks like
[check this](https://developers.google.com/machine-learning/testing-debugging/metrics/interpretic)

![picture](https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/04-loss-curves-overfitting-underfitting-ideal.jpg)

## 9. Model 1: TinyVGG with data augmentation.
Let's try another modelling experiment this time using the same as before with data augmentation.

### 9.1 Create transform with data augmentation.
"""

# Create trainning transform with TrivialAugmentation
from torchvision import transforms
train_transform_trivial = transforms.Compose([
                                              transforms.Resize(size=(64,64)),
                                              transforms.TrivialAugmentWide(num_magnitude_bins=31),
                                              transforms.ToTensor()
                                            ])

test_transform_simple = transforms.Compose([transforms.Resize(size=(64,64)),
                                            transforms.ToTensor()])

"""### 9.2 train and test `Dataset`'s and `DataLoader`'s with data augmentation."""

# Tur image folder into Datasets
from torchvision import datasets
train_data_augmented = datasets.ImageFolder(root=train_dir,
                                            transform=train_transform_trivial)

test_data_simple = datasets.ImageFolder(root=test_dir,
                                        transform = test_transform_simple)

# Turn our Dataset into DataLoaders
import os
from torch.utils.data import DataLoader
BATCH_SIZE = 32
NUM_WORKERS = os.cpu_count()

torch.manual_seed(42)

train_dataloader_augmented = DataLoader(dataset=train_data_augmented,
                                        batch_size=BATCH_SIZE,
                                        shuffle=True,
                                        num_workers=NUM_WORKERS)

test_dataloader_simple = DataLoader(dataset=test_data_simple,
                                    batch_size=BATCH_SIZE,
                                    shuffle=False,
                                    num_workers=NUM_WORKERS)

"""### 9.3 Construct and train model 1
this time we will be using the same modelarchitechture except this time we have augmented the trainning data.
"""

# Create model_1 and send it to the target device
torch.manual_seed(42)
model_1 = TinyVGG(input_shape=3,
                  hidden_units=10,
                  output_shape=len(train_data_augmented.classes)).to(device)

model_1

"""let's create the loss function,optimizer and call upon our `train()` function to train and evluate our model."""

# set random seeds
torch.manual_seed(42)
torch.cuda.manual_seed(42)

# set number of epochs
NUM_EPOCHS = 5

# setup loss function
loss_fn = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(params=model_1.parameters(),lr=0.001)

# start the timer
from timeit import default_timer as timer
start_time = timer()


# train model 1
model_1_results = train(model=model_1,
                        train_dataloader=train_dataloader_augmented,
                        test_dataloader = test_dataloader_simple,
                        optimizer=optimizer,
                        loss_fn=loss_fn,
                        epochs=NUM_EPOCHS)

end_time =timer()

print(f"Total trainning time for model_1 : {end_time-start_time:.3f} seconds")

"""### 9.4 Plot the loss curves of model 1"""

plot_loss_curves(model_1_results)

"""## 10. Compare model results
methods todo this
 - Hard coding
 - PyTorch + Tensorboard [link text](https://pytorch.org/docs/stable/tensorboard.html)
 - Weights & Biases [link text](https://wandb.ai/gencodec)
 - MLFlow [link text](https://mlflow.org/docs/latest/python_api/mlflow.pytorch.html)
"""

import pandas as pd
model_0_df = pd.DataFrame(model_0_results)
model_1_df = pd.DataFrame(model_1_results)

model_0_df

model_1_df

# setup a plot
plt.figure(figsize=(15,10))

# Get number of epochs
epochs = range(len(model_0_df))

# plot train loss
plt.subplot(2,2,1)
plt.plot(epochs,model_0_df["train_loss"],label="Model 0")
plt.plot(epochs,model_1_df["train_loss"],label="Model 1")
plt.title("Train Loss")
plt.xlabel("Epochs")
plt.legend()


# plot train loss
plt.subplot(2,2,2)
plt.plot(epochs,model_0_df["test_loss"],label="Model 0")
plt.plot(epochs,model_1_df["test_loss"],label="Model 1")
plt.title("Test Loss")
plt.xlabel("Epochs")
plt.legend()


# plot train accuracy
plt.subplot(2,2,3)
plt.plot(epochs,model_0_df["train_acc"],label="Model 0")
plt.plot(epochs,model_1_df["train_acc"],label="Model 1")
plt.title("Train Accuracy")
plt.xlabel("Epochs")
plt.legend()


# plot test accuracy
plt.subplot(2,2,4)
plt.plot(epochs,model_0_df["test_acc"],label="Model 0")
plt.plot(epochs,model_1_df["test_acc"],label="Model 1")
plt.title("Test Accuracy")
plt.xlabel("Epochs")
plt.legend()

"""## 11. Making prediction on a custom image"""

# download custom image
import requests
# setup custom image path
custom_image_path = data_path / "pizza-dad.jpeg"

if not custom_image_path.is_file():
  with open(custom_image_path,"wb") as f:
    # download from github
    request = requests.get('https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/04-pizza-dad.jpeg')
    print(f"Downloading {custom_image_path}....")
    f.write(request.content)

else:
  print("Image already exists")

"""### 11.1 Loading in a custom image with PyTorch
* In tensor form with datatype (torch.float32)
* of shape 64x64x3
"""

custom_image_path

import torchvision

# read in custom image
custom_image_uint8 = torchvision.io.read_image(str(custom_image_path))
print(f"Custom image tensor :\n {custom_image_uint8}")
print(f"Custom image shape : {custom_image_uint8.shape}")
print(f"Custom image datatype : {custom_image_uint8.dtype}")

plt.imshow(custom_image_uint8.permute(1,2,0))

"""### 11.2 Making a prediction on a custom image with a trained PyTorch model"""

## Load in the custom image and conver to float32
custom_image  = torchvision.io.read_image(str(custom_image_path)).type(torch.float32)/255
custom_image

plt.imshow(custom_image.permute(1,2,0))

# create transform pipeline to resize the image
custom_image_transform = transforms.Compose([
    transforms.Resize(size=(64,64))
])

# Transform target image
custom_image_transformed = custom_image_transform(custom_image)

# Print out the shapes
print(f"Original shape : {custom_image.shape}")
print(f"Transformed shape : {custom_image_transformed.shape}")

plt.imshow(custom_image_transformed.permute(1,2,0))

model_1.eval()
with torch.inference_mode():
  # custom_image_pred = model_1(custom_image_transformed.to(device))
  # Added a batch size
  custom_image_pred = model_1(custom_image_transformed.unsqueeze(0).to(device))

custom_image_pred

class_names

"""Note to make predictions on a custom image
* load the image and turn it into a tensor
* make sure the data type to float32
* make sure the image was the same shape as data the model was trained on (3,64,64) with batch size (1,3,64,64)
* make sure image was on the same device as out model.
"""

# convert logits to prediction probabilities
custom_image_preb_probs = torch.softmax(custom_image_pred,dim=1)
custom_image_preb_probs

# Convert prediction probs to prediction labels
custom_image_pred_label = torch.argmax(custom_image_preb_probs,dim=1)
custom_image_pred_label

class_names[custom_image_pred_label]

"""### 11.3 Putting custom image prediction together : building a function"""

def pred_and_plot_image(model: torch.nn.Module,
                        image_path :str,
                        class_names: List[str] = None,
                        transform = None,
                        device=device):
  # Load in the image
  target_image = torchvision.io.read_image(str(image_path)).type(torch.float32)

  target_image = target_image/255

  # Transform if necessary
  if transform:
    target_image  = transform(target_image)

  # Make sure the model is on the target device
  model.to(device)

  # Turn on eval mode
  model.eval()
  with torch.inference_mode():
    # Add an extra dimension to the image
    target_image = target_image.unsqueeze(0)

    # Make predictions on the image with an extra dimension
    target_image_pred = model(target_image.to(device))

  # Conver logits -> pred probs
  target_image_pred_probs = torch.softmax(target_image_pred,dim=1)

  # conver pred probs -> pred labels
  target_image_pred_label = torch.argmax(target_image_pred_probs,dim=1)


  # plot the image alongside the prediction and prediction probability
  plt.imshow(target_image.squeeze().permute(1,2,0))

  if class_names:
    title = f"Pred: {class_names[target_image_pred_label.cpu()]} | Prob: {target_image_pred_probs.max().cpu():.3f}"
  else:
    title = f"Pred: {target_image_pred_label} | Prob: {target_image_pred_probs.max().cpu():.3f}"

  plt.title(title)
  plt.axis(False);

# Pred on custom image with model 1
pred_and_plot_image(model=model_1,
                    image_path=custom_image_path,
                    class_names=class_names,
                    transform=custom_image_transform,
                    device=device)

pred_and_plot_image(model=model_0,
                    image_path=custom_image_path,
                    class_names=class_names,
                    transform=custom_image_transform,
                    device=device)

